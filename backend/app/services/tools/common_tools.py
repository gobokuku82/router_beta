from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from typing import Annotated
import requests
import json
from dotenv import load_dotenv

load_dotenv()

@tool
def check_policy_violation(content: Annotated[str, "ì‘ì„±ëœ ë¬¸ì„œ ë³¸ë¬¸"]) -> str:
    """ì‘ì„±ëœ ë¬¸ì„œ ë‚´ìš©ì´ íšŒì‚¬ ê·œì •ì„ ìœ„ë°˜í•˜ëŠ”ì§€ LLMê³¼ OpenSearchë¥¼ í†µí•´ ê²€ì‚¬í•©ë‹ˆë‹¤."""
    
    try:
        # 1ë‹¨ê³„: LLMì„ ì‚¬ìš©í•´ ê·œì • í™•ì¸ì´ í•„ìš”í•œ ë¬¸êµ¬ ì¶”ì¶œ
        llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
        
        extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ì•„ë˜ ê·œì¹™ì„ ì§€í‚¤ë©´ì„œ í–‰ìœ„ ë‹¨ìœ„ë¡œ íŒë‹¨ ê°€ëŠ¥í•œ ë¬¸êµ¬ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

- í–‰ìœ„ ë‹¨ìœ„ë€ ì‹œê°„, ì¥ì†Œ, ì¸ë¬¼, í–‰ìœ„, ëª©ì , ê²°ê³¼, ë¹„ìš© ë“±ì´ í•˜ë‚˜ì˜ ì‚¬ê±´ì²˜ëŸ¼ ë¬¶ì—¬ ê¸°ìˆ ëœ ë¬¸ì¥ ë˜ëŠ” ì ˆì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
- ê³ ê°ì •ë³´, ë‹´ë‹¹ì, ë°©ë¬¸ì ê°™ì€ ê°œì¸ì •ë³´ ë‚´ìš©ì€ íŒë‹¨ ëŒ€ìƒì—ì„œ ì œì™¸í•˜ì„¸ìš”.
- ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ìœ„ë¡œ í•˜ë‚˜ì˜ í–‰ìœ„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ë˜, ë„ˆë¬´ ì˜ê²Œ ìª¼ê°œì§€ ë§ê³  ê·œì • ìœ„ë°˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆì„ ì •ë„ì˜ ì •ë³´ëŸ‰ì„ ê°–ì¶”ë„ë¡ í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ê²°ê³¼ë¥¼ JSON ë¬¸ìì—´ ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
- ê·œì • í™•ì¸ì— í™œìš©í• ë§Œí•œ ë¬¸ì¥ì´ ì—†ë‹¤ê³  íŒë‹¨ë˜ë©´ [] ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

ì…ë ¥ ì˜ˆì‹œ:
25ë…„ 7ì›” 25ì¼ì— ì œí’ˆì„¤ëª…íšŒê°€ ì‹œí–‰ë¬ê³  ì œí’ˆì„¤ëª…íšŒë¡œ êµ¬ë¶„ë¼ ê¹€ë„ìœ¤ PMì´ ì°¸ì„í•˜ì˜€ê³  ì¥ì†ŒëŠ” ì½”ì—‘ìŠ¤ Bí™€ì—ì„œ ì§„í–‰ë¬ì–´ ì„¤ëª…íšŒì— ì–¸ê¸‰ëœ ì œí’ˆì€ í…í…ì´ê³  ì œí’ˆ ë¦¬ë‰´ì–¼ ì†Œê°œê°€ ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ëª©ì ì´ì˜€ì§€ ì£¼ìš”ë‚´ìš©ìœ¼ë¡œëŠ” ê¸°ì¡´ ì œí’ˆì˜ ë¬¸ì œì ê³¼ ë¦¬ë‰´ì–¼ ë˜ë©´ì„œ ë°”ë€ì ê³¼ ì˜ì–‘ì„±ë¶„ ì†Œê°œì•¼ ì°¸ì„í•œ ì§ì›ë“¤ì€ ì˜ì—…íŒ€ ì†í˜„ì„±, ì´ìš©ê·œ, ì†ì˜ì‹ ì´ê³  ë³´ê±´ì˜ë£Œì „ë¬¸ê°€ëŠ” ì„œìš¸ëŒ€í•™ë³‘ì› í—ˆí•œê²° ì—°ì„¸ëŒ€í•™ë³‘ì› ìµœë¬¸ì˜ êµìˆ˜ê°€ ì°¸ì—¬í–ˆì–´ ì´í›„ ì €ë…ì‹ì‚¬ ìë¦¬ë¥¼ ê°€ì¡Œê³  ë©”ë‰´ëŠ” ì¹˜í‚¨ì´ê³  ì‚¬ìš©í•œ ê¸ˆì•¡ì€ 10ë§Œì›ì´ì•¼ ì£¼ë¥˜ëŠ” ì†Œì£¼ 2ë³‘, ë§¥ì£¼ 6ë³‘ì„ ë§ˆì…¨ê³  ì¸ë‹¹ê¸ˆì•¡ì€ 2ë§Œì›ì´ ë‚˜ì™”ì–´

ì¶œë ¥ ì˜ˆì‹œ(jsoní˜•íƒœ):
[
  "25ë…„ 7ì›” 25ì¼ì— ì œí’ˆì„¤ëª…íšŒê°€ ì‹œí–‰ëê³  ì œí’ˆì„¤ëª…íšŒë¡œ êµ¬ë¶„ë¼ ê¹€ë„ìœ¤ PMì´ ì°¸ì„í•˜ì˜€ê³  ì¥ì†ŒëŠ” ì½”ì—‘ìŠ¤ Bí™€ì—ì„œ ì§„í–‰ëì–´",
  "ì„¤ëª…íšŒì— ì–¸ê¸‰ëœ ì œí’ˆì€ í…í…ì´ê³  ì œí’ˆ ë¦¬ë‰´ì–¼ ì†Œê°œê°€ ì œí’ˆì„¤ëª…íšŒ ì‹œí–‰ ëª©ì ì´ì—ˆì§€ ì£¼ìš”ë‚´ìš©ìœ¼ë¡œëŠ” ê¸°ì¡´ ì œí’ˆì˜ ë¬¸ì œì ê³¼ ë¦¬ë‰´ì–¼ë˜ë©´ì„œ ë°”ë€ ì , ì˜ì–‘ì„±ë¶„ ì†Œê°œì•¼",
  "ì°¸ì„í•œ ì§ì›ë“¤ì€ ì˜ì—…íŒ€ ì†í˜„ì„±, ì´ìš©ê·œ, ì†ì˜ì‹ì´ê³  ë³´ê±´ì˜ë£Œì „ë¬¸ê°€ëŠ” ì„œìš¸ëŒ€í•™ë³‘ì› í—ˆí•œê²°, ì—°ì„¸ëŒ€í•™ë³‘ì› ìµœë¬¸ì˜ êµìˆ˜ê°€ ì°¸ì—¬í–ˆì–´",
  "ì´í›„ ì €ë…ì‹ì‚¬ ìë¦¬ë¥¼ ê°€ì¡Œê³  ë©”ë‰´ëŠ” ì¹˜í‚¨ì´ë©° ì‚¬ìš©í•œ ê¸ˆì•¡ì€ 10ë§Œì›ì´ì•¼ ì£¼ë¥˜ëŠ” ì†Œì£¼ 2ë³‘, ë§¥ì£¼ 6ë³‘ì„ ë§ˆì…¨ê³  ì¸ë‹¹ ê¸ˆì•¡ì€ 2ë§Œì›ì´ ë‚˜ì™”ì–´"
]
             ì¶œë ¥ ì˜ˆì‹œ:


            """),
            ("human", "{content}")
        ])
        
        response = llm.invoke(extraction_prompt.format_messages(content=content))
        extracted_text = response.content.strip()
        
        print(f"ğŸ“‹ LLM ë¬¸êµ¬ ì¶”ì¶œ ê²°ê³¼: {extracted_text}")
        
        # JSON íŒŒì‹±
        try:
            if extracted_text.startswith('[') and extracted_text.endswith(']'):
                policy_phrases = json.loads(extracted_text)
            else:
                # JSON í˜•íƒœê°€ ì•„ë‹Œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                policy_phrases = []
        except json.JSONDecodeError:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬")
            policy_phrases = []
        
        if not policy_phrases:
            print("âœ… ê·œì • í™•ì¸ì´ í•„ìš”í•œ ë¬¸êµ¬ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return "OK"
        
        print(f"ğŸ” ì¶”ì¶œëœ ê·œì • í™•ì¸ ëŒ€ìƒ ë¬¸êµ¬: {policy_phrases}")
        
        # 2ë‹¨ê³„: FastAPIë¥¼ í†µí•´ ê° ë¬¸êµ¬ë³„ë¡œ ìœ ì‚¬í•œ ê·œì • ì •ë³´ ê²€ìƒ‰
        violations = []
        fastapi_url = "http://localhost:8010/qa/question"
        
        for phrase in policy_phrases:
            try:
                # FastAPI í˜¸ì¶œ - ì˜¬ë°”ë¥¸ í˜ì´ë¡œë“œ í˜•ì‹ ì‚¬ìš©
                payload = {
                    "question": phrase,
                    "top_k": 5,
                    "include_summary": True,
                    "include_sources": True
                }
                
                response = requests.post(
                    fastapi_url,
                    json=payload,
                    headers={"Content-Type": "application/json"},
                    timeout=30
                )
                
                if response.status_code == 200:
                    api_result = response.json()
                    if api_result.get('success', False):
                        search_results = api_result.get('search_results', [])
                        print(f"ğŸ“Š '{phrase}' ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
                        
                        # 3ë‹¨ê³„: LLMì„ ì‚¬ìš©í•´ ì¶”ì¶œëœ ê·œì • ì •ë³´ì™€ ë¹„êµí•˜ì—¬ ìœ„ë°˜ ì—¬ë¶€ íŒë‹¨
                        violation_result = _check_phrase_against_regulations(phrase, search_results, llm)
                        if violation_result != "OK":
                            violations.append(f"{phrase}: {violation_result}")
                    else:
                        print(f"âš ï¸ API ì‘ë‹µ ì‹¤íŒ¨ ({phrase}): {api_result}")
                        violations.append(f"{phrase}: API ì‘ë‹µ ì˜¤ë¥˜")
                        
                else:
                    print(f"âš ï¸ FastAPI í˜¸ì¶œ ì‹¤íŒ¨ ({phrase}): {response.status_code}")
                    violations.append(f"{phrase}: ê·œì • ê²€ìƒ‰ ì‹¤íŒ¨ (HTTP {response.status_code})")
                    
            except requests.exceptions.RequestException as e:
                print(f"âš ï¸ API í˜¸ì¶œ ì˜¤ë¥˜ ({phrase}): {e}")
                violations.append(f"{phrase}: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ë¡œ ê·œì • í™•ì¸ ë¶ˆê°€")
            except Exception as e:
                print(f"âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({phrase}): {e}")
                violations.append(f"{phrase}: ì²˜ë¦¬ ì˜¤ë¥˜ - {str(e)}")
        
        # ìµœì¢… ê²°ê³¼ ë°˜í™˜
        actual_violations = []
        for violation in violations:
            # "OK"ê°€ í¬í•¨ë˜ì§€ ì•Šì€ ì‹¤ì œ ìœ„ë°˜ ì‚¬í•­ë§Œ ì¶”ê°€
            if ": OK" not in violation and violation.strip() != "OK":
                actual_violations.append(violation)
        
        if actual_violations:
            return " | ".join(actual_violations)
        else:
            return "OK"
            
    except Exception as e:
        print(f"âŒ ê·œì • ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"ê·œì • ê²€ì‚¬ ì˜¤ë¥˜: {str(e)}"

def _check_phrase_against_regulations(phrase: str, search_results: list, llm: ChatOpenAI) -> str:
    """ì¶”ì¶œëœ ë¬¸êµ¬ë¥¼ ê·œì • ì •ë³´ì™€ ë¹„êµí•˜ì—¬ ìœ„ë°˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
    
    try:
        if not search_results:
            return "ê´€ë ¨ ê·œì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
        
        # ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì‚¬ìš© (ë„ˆë¬´ ë§ì€ ì •ë³´ ë°©ì§€)
        top_results = search_results[:3]
        regulations_text = "\n\n".join([
            f"ê·œì • {i+1} (ì ìˆ˜: {result.get('score', 0):.2f}):\n{result.get('source', {}).get('content', '')}" 
            for i, result in enumerate(top_results)
        ])

        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸(ìœ„ë°˜ ì‚¬í•­ ë‚¨ë°œí•¨)
        # ë‹¤ìŒ ë¬¸êµ¬ê°€ ì œê³µëœ íšŒì‚¬ ê·œì •ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

        # ë¶„ì„ ê¸°ì¤€:
        # 1. ëª…í™•í•œ ê·œì • ìœ„ë°˜ì´ ìˆëŠ”ì§€ í™•ì¸
        # 2. ì ì¬ì  ìœ„í—˜ì´ë‚˜ ì£¼ì˜ê°€ í•„ìš”í•œ ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸
        # 3. ê·œì •ì— ëª…ì‹œë˜ì§€ ì•Šì•˜ë”ë¼ë„ ì¼ë°˜ì ì¸ ì»´í”Œë¼ì´ì–¸ìŠ¤ ê´€ì ì—ì„œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸

        # ì‘ë‹µ í˜•ì‹:
        # - ìœ„ë°˜ì´ë‚˜ ë¬¸ì œê°€ ì—†ìœ¼ë©´: "OK"
        # - ë¬¸ì œê°€ ìˆìœ¼ë©´: êµ¬ì²´ì ì¸ ìœ„ë°˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…
        validation_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¤ìŒ ë¬¸êµ¬ê°€ ì œê³µëœ íšŒì‚¬ ê·œì •ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
1. ëª…í™•í•˜ê²Œ ê·œì • ìœ„ë°˜ì´ ìˆëŠ”ì§€ í™•ì¸
2. ìœ„ë°˜ ë¬¸ì œê°€ ìˆì–´ë³´ì´ëŠ” ê²ƒì´ ì•„ë‹Œ ëª…í™•í•˜ê²Œ ê·œì •ì„ ìœ„ë°˜í•œê²ƒë§Œ ë¬¸ì œë¡œ íŒë‹¨

ì‘ë‹µ í˜•ì‹:
- ìœ„ë°˜ì´ë‚˜ ë¬¸ì œê°€ ì—†ìœ¼ë©´: "OK"
- ë¬¸ì œê°€ ìˆìœ¼ë©´: êµ¬ì²´ì ì¸ ìœ„ë°˜ ë‚´ìš©ì„ ê°„ë‹¨íˆ ì„¤ëª…
            """),
            ("human", "í™•ì¸í•  ë¬¸êµ¬: {phrase}\n\nê´€ë ¨ ê·œì • ì •ë³´:\n{regulations}")
        ])
        
        response = llm.invoke(validation_prompt.format_messages(
            phrase=phrase, 
            regulations=regulations_text
        ))
        
        result = response.content.strip()
        print(f"ğŸ” '{phrase}' ê·œì • ê²€ì‚¬ ê²°ê³¼: {result[:100]}{'...' if len(result) > 100 else ''}")
        
        return result
        
    except Exception as e:
        print(f"âš ï¸ ê·œì • ë¹„êµ ì¤‘ ì˜¤ë¥˜: {e}")
        return f"ê·œì • ë¹„êµ ì˜¤ë¥˜: {str(e)}"

@tool
def convert_structured_to_natural_text(structured_data: Annotated[str, "JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë°ì´í„°"]) -> str:
    """êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì›ë¬¸ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    
    try:
        # JSON íŒŒì‹±
        try:
            if isinstance(structured_data, str):
                import json
                data = json.loads(structured_data) if structured_data.startswith('{') else eval(structured_data)
            else:
                data = structured_data
        except (json.JSONDecodeError, SyntaxError) as e:
            return f"ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
        
        # LLMì„ ì‚¬ìš©í•´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜
        llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
        
        conversion_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ì£¼ì–´ì§„ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ë³€í™˜ ê·œì¹™:
1. ëª¨ë“  ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
2. ìì—°ìŠ¤ëŸ½ê³  ì½ê¸° ì‰¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”
3. êµ¬ì–´ì²´ í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ì„¸ìš” (ì˜ˆ: ~ì´ì•¼, ~ì•¼, ~ìŒ, ~ì§€)
4. ë…¼ë¦¬ì ì¸ ìˆœì„œë¡œ ì •ë³´ë¥¼ ë°°ì¹˜í•´ì£¼ì„¸ìš”
5. ë‚ ì§œ, ì—°ë½ì²˜, ì‚¬ì´íŠ¸ ë“±ì˜ ì •í™•í•œ ì •ë³´ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•´ì£¼ì„¸ìš”

ì˜ˆì‹œ ë³€í™˜:
ì…ë ¥: {{"ë°©ë¬¸ì œëª©": "ABCë³‘ì› ë°©ë¬¸", "ë°©ë¬¸ë‚ ì§œ": "240101", "Client": "ABCë³‘ì›"}}
ì¶œë ¥: ë°©ë¬¸ ì œëª©ì€ ABCë³‘ì› ë°©ë¬¸ì´ê³  ë°©ë¬¸ì¼ì€ 240101ì´ê³  clientëŠ” ABCë³‘ì›ì´ì•¼

í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ëœ ë¬¸ì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """),
            ("human", "ë‹¤ìŒ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì›ë¬¸ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:\n\n{data}")
        ])
        
        # ë°ì´í„°ë¥¼ ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜
        data_str = str(data) if not isinstance(data, str) else data
        
        response = llm.invoke(conversion_prompt.format_messages(data=data_str))
        natural_text = response.content.strip()
        
        print(f"ğŸ“ êµ¬ì¡°í™”ëœ ë°ì´í„° â†’ ìì—°ì–´ ë³€í™˜ ì™„ë£Œ")
        print(f"ğŸ” ë³€í™˜ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(natural_text)}ì")
        
        return natural_text
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"ë°ì´í„° ë³€í™˜ ì˜¤ë¥˜: {str(e)}"

@tool
def separate_document_type_and_content(user_input: Annotated[str, "ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸"]) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¬¸ì„œ ì–‘ì‹ ë¶„ë¥˜ì™€ ê´€ë ¨ëœ ë‚´ìš©ê³¼ ë¬¸ì„œ ì–‘ì‹ì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0.1)
        
        separation_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ë¬¸ì„œ ì–‘ì‹ ë¶„ë¥˜ì™€ ê´€ë ¨ëœ ë‚´ìš©ê³¼ ì‹¤ì œ ë¬¸ì„œì— ë“¤ì–´ê°ˆ ë‚´ìš©ì„ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.

ë¶„ë¦¬ ê¸°ì¤€:
1. ë¬¸ì„œ ì–‘ì‹ ë¶„ë¥˜: "~ì„/ë¥¼ ì‘ì„±í• ê±°ì•¼", "~ì„œë¥˜ë¥¼ ë§Œë“¤ì–´ì¤˜", "~ê³„íšì„œ ì‘ì„±", "~ë³´ê³ ì„œ ì¤€ë¹„" ë“± ë¬¸ì„œì˜ ì¢…ë¥˜ë‚˜ í˜•íƒœë¥¼ ëª…ì‹œí•˜ëŠ” ë¶€ë¶„
2. ë¬¸ì„œ ë‚´ìš©: ì‹¤ì œ ë¬¸ì„œì— í¬í•¨ë  êµ¬ì²´ì ì¸ ì •ë³´, ë°ì´í„°, ë‚´ìš©

ì‘ë‹µ í˜•ì‹ì€ JSONìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{
    "document_type": "ë¬¸ì„œ ì–‘ì‹ ë¶„ë¥˜ ê´€ë ¨ ë‚´ìš©",
    "content": "ë¬¸ì„œì— ë“¤ì–´ê°ˆ ì‹¤ì œ ë‚´ìš©"
}}

ì˜ˆì‹œ:
ì…ë ¥: "ì œí’ˆì„¤ëª…íšŒ ê³„íšì„œë¥¼ ì‘ì„±í• ê±°ì•¼. 25ë…„ 7ì›” 25ì¼ì— ì œí’ˆì„¤ëª…íšŒê°€ ì‹œí–‰ë˜ë©°..."
ì¶œë ¥: {{
    "document_type": "ì œí’ˆì„¤ëª…íšŒ ê³„íšì„œë¥¼ ì‘ì„±í• ê±°ì•¼",
    "content": "25ë…„ 7ì›” 25ì¼ì— ì œí’ˆì„¤ëª…íšŒê°€ ì‹œí–‰ë˜ë©°..."
}}

ë§Œì•½ ë¬¸ì„œ ì–‘ì‹ ë¶„ë¥˜ ë¶€ë¶„ì´ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´ document_typeì„ ë¹ˆ ë¬¸ìì—´ë¡œ, 
ë¬¸ì„œ ë‚´ìš©ì´ ì—†ë‹¤ë©´ contentë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•´ì£¼ì„¸ìš”.
            """),
            ("human", "{user_input}")
        ])
        
        response = llm.invoke(separation_prompt.format_messages(user_input=user_input))
        result = response.content.strip()
        
        print(f"ğŸ“‹ ë¬¸ì„œ ë¶„ë¥˜ ë° ë‚´ìš© ë¶„ë¦¬ ê²°ê³¼: {result}")
        
        # JSON ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ``` í˜•íƒœ)
        if result.startswith('```json'):
            result = result.replace('```json', '').replace('```', '').strip()
        elif result.startswith('```'):
            result = result.replace('```', '').strip()
        
        # JSON íŒŒì‹± ê²€ì¦
        try:
            parsed = json.loads(result)
            if 'document_type' in parsed and 'content' in parsed:
                return result
            else:
                print("âš ï¸ í•„ìˆ˜ í‚¤ê°€ ëˆ„ë½ëœ ì‘ë‹µ")
                return json.dumps({
                    "document_type": "",
                    "content": user_input
                }, ensure_ascii=False)
        except json.JSONDecodeError:
            print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨")
            return json.dumps({
                "document_type": "",
                "content": user_input
            }, ensure_ascii=False)
        
    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ë¶„ë¥˜ ë° ë‚´ìš© ë¶„ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return json.dumps({
            "document_type": "",
            "content": user_input
        }, ensure_ascii=False)