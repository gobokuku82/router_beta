"""
í†µí•© íƒœìŠ¤í¬ ë¼ìš°í„°
ë‹¨ì¼/ë©€í‹° íƒœìŠ¤í¬ë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  í†µí•© ì²˜ë¦¬
"""
import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from openai import AsyncOpenAI
from pathlib import Path
from dotenv import load_dotenv

from .router_agent import RouterAgent, AVAILABLE_AGENT_IDS
from .prompts import get_task_decomposition_prompt
from ..common.handlers import agent_handlers

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# .env íŒŒì¼ ë¡œë“œ
env_path = Path(__file__).parent.parent.parent / ".env"
if env_path.exists():
    load_dotenv(env_path)
    logger.info(f"Loaded .env from: {env_path}")


class TaskRouter:
    """í†µí•© íƒœìŠ¤í¬ ë¼ìš°í„°"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.router_agent = RouterAgent()  # ê¸°ì¡´ ë¼ìš°í„° í™œìš©
        self.agent_handlers = agent_handlers
        
    async def process_query(self, query: str, session_id: str, messages: List[Dict] = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë©”ì„œë“œ
        
        Args:
            query: ì‚¬ìš©ì ì…ë ¥
            session_id: ì„¸ì…˜ ID
            messages: ì´ì „ ëŒ€í™” ê¸°ë¡
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            # 1. íƒœìŠ¤í¬ ë¶„í•´
            tasks = await self._decompose_query(query)
            
            if not tasks:
                # ì—ì´ì „íŠ¸ê°€ í•„ìš”ì—†ëŠ” ì¼ë°˜ ëŒ€í™”
                return {
                    "type": "general",
                    "response": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
                    "tasks": []
                }
            
            # 2. docs_agentê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_docs_agent = any(task.get("agent") in ["docs_agent", "create_document_agent"] for task in tasks)
            
            # 3. ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
            execution_plan = self._create_execution_plan(tasks)
            
            # 4. íƒœìŠ¤í¬ ì‹¤í–‰
            if len(tasks) == 1:
                # ë‹¨ì¼ íƒœìŠ¤í¬
                result = await self._execute_single_task(tasks[0], session_id, messages)
                return {
                    "type": "single",
                    "response": result,
                    "tasks": tasks
                }
            else:
                # ë©€í‹° íƒœìŠ¤í¬ì¸ë° docs_agentê°€ í¬í•¨ëœ ê²½ìš°
                if has_docs_agent:
                    # docs_agentëŠ” ëŒ€í™”í˜•ì´ë¯€ë¡œ ë©€í‹° íƒœìŠ¤í¬ë¡œ ì²˜ë¦¬í•˜ë©´ ì•ˆë¨
                    # ë‹¤ë¥¸ íƒœìŠ¤í¬ë“¤ë§Œ ë¨¼ì € ì²˜ë¦¬í•˜ê³  docs_agentëŠ” ë³„ë„ ì•ˆë‚´
                    non_docs_tasks = [t for t in tasks if t.get("agent") not in ["docs_agent", "create_document_agent"]]
                    docs_tasks = [t for t in tasks if t.get("agent") in ["docs_agent", "create_document_agent"]]
                    
                    if non_docs_tasks:
                        # docs_agentê°€ ì•„ë‹Œ íƒœìŠ¤í¬ë“¤ë§Œ ì‹¤í–‰
                        results = await self._execute_multi_tasks(non_docs_tasks, self._create_execution_plan(non_docs_tasks), session_id, messages)
                        aggregated = self._aggregate_results(results, non_docs_tasks)
                        
                        # docs_agentëŠ” ë³„ë„ë¡œ ì•ˆë‚´
                        if docs_tasks:
                            aggregated["summary"] += f"\n\nğŸ“ ë¬¸ì„œ ìƒì„±ì€ ëŒ€í™”í˜• ì‘ì—…ì´ë¯€ë¡œ ë³„ë„ë¡œ ì§„í–‰í•´ì£¼ì„¸ìš”:\n"
                            for task in docs_tasks:
                                aggregated["summary"] += f"- {task['description']}\n"
                        
                        return {
                            "type": "multi",
                            "response": aggregated,
                            "tasks": non_docs_tasks,
                            "detailed_results": results,
                            "execution_plan": self._create_execution_plan(non_docs_tasks),
                            "pending_docs_tasks": docs_tasks
                        }
                    else:
                        # ëª¨ë“  íƒœìŠ¤í¬ê°€ docs_agentì¸ ê²½ìš°
                        return {
                            "type": "docs_only",
                            "response": "ë¬¸ì„œ ìƒì„±ì€ ëŒ€í™”í˜• ì‘ì—…ì…ë‹ˆë‹¤. ê° ë¬¸ì„œë¥¼ ê°œë³„ì ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.",
                            "tasks": docs_tasks
                        }
                else:
                    # docs_agentê°€ ì—†ëŠ” ì¼ë°˜ ë©€í‹° íƒœìŠ¤í¬
                    results = await self._execute_multi_tasks(tasks, execution_plan, session_id, messages)
                    aggregated = self._aggregate_results(results, tasks)
                    return {
                        "type": "multi",
                        "response": aggregated,  # ì´ì œ êµ¬ì¡°í™”ëœ ê°ì²´
                        "tasks": tasks,
                        "detailed_results": results,
                        "execution_plan": execution_plan
                    }
                
        except Exception as e:
            logger.error(f"Task routing failed: {e}")
            raise
    
    async def _decompose_query(self, query: str) -> List[Dict]:
        """ì¿¼ë¦¬ë¥¼ íƒœìŠ¤í¬ë“¤ë¡œ ë¶„í•´"""
        try:
            prompt = get_task_decomposition_prompt(query)
            
            response = await self.client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a task decomposition expert. Always respond with valid JSON only, no code blocks."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1
            )
            
            # ì‘ë‹µ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            response_content = response.choices[0].message.content
            logger.debug(f"GPT Response: {response_content}")
            
            # JSON íŒŒì‹± (ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in response_content:
                response_content = response_content.split("```json")[1].split("```")[0]
            elif "```" in response_content:
                response_content = response_content.split("```")[1].split("```")[0]
            
            # ì „í›„ ê³µë°± ì œê±° í›„ íŒŒì‹±
            result = json.loads(response_content.strip())
            tasks = result.get("tasks", [])
            
            logger.info(f"Query decomposed into {len(tasks)} tasks")
            return tasks
            
        except Exception as e:
            logger.error(f"Task decomposition failed: {e}")
            # Fallback: ì „ì²´ë¥¼ í•˜ë‚˜ì˜ íƒœìŠ¤í¬ë¡œ ì²˜ë¦¬
            return [{
                "id": 0,
                "description": query,
                "agent": await self.router_agent.classify(query, []),
                "query": query,
                "depends_on": [],
                "parallel_group": 0
            }]
    
    def _create_execution_plan(self, tasks: List[Dict]) -> Dict[str, List[int]]:
        """ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (ë³‘ë ¬/ìˆœì°¨ ê·¸ë£¹í•‘)"""
        plan = {}
        
        for task in tasks:
            group = task.get("parallel_group", 0)
            if group not in plan:
                plan[group] = []
            plan[group].append(task["id"])
            
        return plan
    
    async def _execute_single_task(self, task: Dict, session_id: str, messages: List[Dict]) -> str:
        """ë‹¨ì¼ íƒœìŠ¤í¬ ì‹¤í–‰"""
        agent_name = task["agent"]
        query = task["query"]
        
        # ì—ì´ì „íŠ¸ í•¸ë“¤ëŸ¬ ê°€ì ¸ì˜¤ê¸°
        if agent_name not in self.agent_handlers:
            logger.error(f"Unknown agent: {agent_name}")
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. {agent_name} ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        handler = self.agent_handlers[agent_name]
        
        try:
            # ì—ì´ì „íŠ¸ ì‹¤í–‰ - ì—ì´ì „íŠ¸ë³„ë¡œ ë‹¤ë¥¸ ì¸ì ì²˜ë¦¬
            if agent_name in ["employee_agent", "client_agent"]:
                # 3ê°œ ì¸ìë¥¼ ë°›ëŠ” ì—ì´ì „íŠ¸
                result = await handler(query, session_id, messages or [])
            else:
                # 2ê°œ ì¸ìë§Œ ë°›ëŠ” ì—ì´ì „íŠ¸ (search_agent, docs_agent)
                result = await handler(query, session_id)
            return result
        except Exception as e:
            logger.error(f"Agent execution failed: {agent_name} - {e}")
            return f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _execute_multi_tasks(self, tasks: List[Dict], execution_plan: Dict[str, List[int]], 
                                   session_id: str, messages: List[Dict]) -> Dict[int, Any]:
        """ë©€í‹° íƒœìŠ¤í¬ ì‹¤í–‰"""
        results = {}
        task_map = {task["id"]: task for task in tasks}
        
        # ê·¸ë£¹ë³„ë¡œ ìˆœì°¨ ì‹¤í–‰
        for group_num in sorted(execution_plan.keys()):
            group_tasks = execution_plan[group_num]
            
            # ê·¸ë£¹ ë‚´ íƒœìŠ¤í¬ë“¤ì€ ë³‘ë ¬ ì‹¤í–‰
            group_results = await asyncio.gather(*[
                self._execute_task_with_context(
                    task_map[task_id], 
                    results, 
                    session_id, 
                    messages
                )
                for task_id in group_tasks
            ])
            
            # ê²°ê³¼ ì €ì¥
            for task_id, result in zip(group_tasks, group_results):
                results[task_id] = result
                
        return results
    
    async def _execute_task_with_context(self, task: Dict, previous_results: Dict[int, Any],
                                       session_id: str, messages: List[Dict]) -> Any:
        """ì´ì „ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ íƒœìŠ¤í¬ ì‹¤í–‰"""
        # ì˜ì¡´ì„±ì´ ìˆëŠ” ê²½ìš° ì´ì „ ê²°ê³¼ë¥¼ ì¿¼ë¦¬ì— ì¶”ê°€
        enhanced_query = task["query"]
        
        if task.get("depends_on"):
            context_parts = []
            for dep_id in task["depends_on"]:
                if dep_id in previous_results:
                    context_parts.append(f"[ì´ì „ ë¶„ì„ ê²°ê³¼ {dep_id}]: {previous_results[dep_id]}")
            
            if context_parts:
                enhanced_query = "\n".join(context_parts) + "\n\n" + enhanced_query
        
        # íƒœìŠ¤í¬ ì‹¤í–‰
        modified_task = task.copy()
        modified_task["query"] = enhanced_query
        
        return await self._execute_single_task(modified_task, session_id, messages)
    
    def _aggregate_results(self, results: Dict[int, Any], tasks: List[Dict]) -> Dict[str, Any]:
        """ë©€í‹° íƒœìŠ¤í¬ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜"""
        if not results:
            return {
                "summary": "ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "steps": []
            }
            
        # íƒœìŠ¤í¬ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì •ë¦¬
        steps = []
        summary_parts = []
        
        for task in sorted(tasks, key=lambda x: x["id"]):
            task_id = task["id"]
            if task_id in results:
                step_info = {
                    "step": task_id + 1,
                    "agent": task["agent"],
                    "description": task["description"],
                    "status": "completed",
                    "result": results[task_id]
                }
                steps.append(step_info)
                summary_parts.append(f"âœ… {task['description']}")
                
        # ì „ì²´ ìš”ì•½
        summary = "ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n" + "\n".join(summary_parts)
        
        return {
            "summary": summary,
            "steps": steps,
            "total_steps": len(tasks),
            "completed_steps": len(steps)
        }


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
task_router = TaskRouter()